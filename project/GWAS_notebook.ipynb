{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55b1bac-24bc-4541-be4d-a44ecab4eafd",
   "metadata": {},
   "source": [
    "## <i>In this project, we will set up a traditional GWAS algorithm and expand on it by performing gene-set level association testing with a certain trait</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ba421-178a-4128-aa8d-6cd20914eb47",
   "metadata": {},
   "source": [
    "#### Set working diretory and import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc9d93-fa29-43b1-b5a4-72c91ac3c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc633c75-5d2c-448e-b35a-bb6fa10c2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "import pandas as pd\n",
    "from hail.plot import show, output_notebook\n",
    "import ipywidgets as widgets\n",
    "from biomart import BiomartServer\n",
    "import io\n",
    "import re\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ast\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "pio.renderers.default = 'jupyterlab'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86afd01-c987-4bba-9278-2d58c8e9fce5",
   "metadata": {},
   "source": [
    "#### Using hail to prepare the data for GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d62bc4-0e22-44f1-a75e-e3dc421be53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize hail and set up env for interactive plot visualization (bokeh)\n",
    "hl.init()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fe102-254b-405c-8e08-b9eed62348ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the vcf file of SNP data and write the raw data into a matrix table (not real data only for practice)\n",
    "vcf = hl.import_vcf(\"BroadE_HailWorkshop2020/resources/1kg.vcf.bgz\", min_partitions=4)\n",
    "vcf.write(\"1kg.mt\", overwrite=True)\n",
    "mt = hl.read_matrix_table(\"1kg.mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032b523-5311-4207-8526-d3f515aff31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62819d01-296a-494a-8778-b1ab3d43ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a row field to display the chromosome number of every variant\n",
    "mt = mt.annotate_rows(contig=mt.locus.contig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7cfef6-c2d9-4bc5-931a-a14db6f5436c",
   "metadata": {},
   "source": [
    "#### Quality control of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4c2e0-a8fc-4871-9c46-07f6740096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute various quality control metrics for every column (individual/sample)\n",
    "mt = hl.sample_qc(mt)\n",
    "\n",
    "#keep the columns (samples) who have a proportion of non-missing genotypes >= 95%\n",
    "mt = mt.filter_cols(mt.sample_qc.call_rate >= 0.95)\n",
    "\n",
    "#compute various QC metrics for every row/variant and adds a new row field with these metrics\n",
    "mt = hl.variant_qc(mt)\n",
    "mt = mt.filter_rows(mt.variant_qc.call_rate > 0.95)\n",
    "\n",
    "#keep variants that have a variance > specified threshold (0.001). The variance here is for the number of alternate alleles every variant has.\n",
    "# An individual can have a genotype of 0 (homozygous reference), 1 (heterozygous), or 2 (homo alternates) for a specific variant. \n",
    "threshold = 0.001\n",
    "mt = mt.filter_rows(hl.agg.stats(mt.GT.n_alt_alleles()).stdev ** 2 > threshold)\n",
    "\n",
    "#keeps variants that have alt allele frequency > 1% for every variant across all samples\n",
    "mt = mt.filter_rows(hl.agg.call_stats(mt.GT, mt.alleles).AF[1] > 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad31c88-4b85-47ee-9ae1-7b63ef1eb5cd",
   "metadata": {},
   "source": [
    "#### We now handle and process the phenotype and covariate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f773f-63f2-42dc-8c42-bc15f8c454d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the phenotype file\n",
    "table = hl.import_table(\"C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\\\\BroadE_HailWorkshop2020\\\\resources\\\\phenotype_file\\\\1kg_annotations.txt\", impute=True, key='s')\n",
    "\n",
    "#filter out the table so that only the samples found in the mt are kept in the table\n",
    "table = table.filter(hl.is_defined(mt.cols()[table.key]))\n",
    "\n",
    "#add column fields using the imported table\n",
    "mt = mt.annotate_cols(\n",
    "    fam_id=mt.s,\n",
    "    ind_id=mt.s,\n",
    "    pat_id=\"NA\",\n",
    "    mat_id=\"NA\",\n",
    "    female=table[mt.s].is_female,\n",
    "    caff=table[mt.s].caffeine_consumption\n",
    ")\n",
    "\n",
    "filtered_table = mt.cols().select(\"ind_id\", \"fam_id\", \"pat_id\", \"mat_id\", \"female\", \"caff\")\n",
    "filtered_table.export(\"C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\\\\BroadE_HailWorkshop2020\\\\resources\\\\phenotype_file\\filtered_1kg_annotations_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c01833-782a-4a74-9710-acf646ca3f7f",
   "metadata": {},
   "source": [
    "#### Create PLINK genotype files from the matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fd181-8f2c-4e48-8389-79e76c96ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.export_plink(mt, 'C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\\\\exported_Gene_Data\\\\PLINK_genotypes_from_hail\\\\test', \n",
    "        fam_id=mt.s, ind_id=mt.s, pat_id=None, mat_id=None, is_female=mt.female, pheno=mt.caff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d091461-9074-4a16-82ac-371626b026ec",
   "metadata": {},
   "source": [
    "#### Preprocessing phenotypes and covariates for Regenie (tool to perform GWAS with enhanced parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fa189-bb46-4ba9-bbd7-f22ecc471ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify 'table' for regenie format:\n",
    "\n",
    "#read the table of phenotypes with tab as delimiter\n",
    "pheno = pd.read_csv(\"BroadE_HailWorkshop2020/resources/filtered_1kg_annotations.txt\", sep=\"\\t\")\n",
    "\n",
    "#Rename the columns to add FamilyID(FID) and IndividualID(IID) for gwas study\n",
    "pheno.columns = ['s', 'IID', 'FID', 'pat_id', 'mat_id', 'is_female', 'caffeine_consumption']\n",
    "\n",
    "#Create a new dataframe via [[]] using subset of columns from original dataframe \n",
    "pheno = pheno[['FID', 'IID', 'caffeine_consumption']]\n",
    "\n",
    "pheno.to_csv('exported_Gene_Data/phenotypes/filtered_pheno.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8295260-47f4-4d90-8fa2-84529db2497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pd.read_csv(\"BroadE_HailWorkshop2020/resources/filtered_1kg_annotations.txt\", sep=\"\\t\")\n",
    "\n",
    "cov.columns = ['s', 'IID', 'FID', 'pat_id', 'mat_id', 'is_female', 'caffeine_consumption']\n",
    "cov['FID'] = cov['IID']   #copy column IID to new column FID\n",
    "\n",
    "cov = cov[['FID', 'IID', 'is_female']]\n",
    "#cov.to_csv(\"C:\\\\Rami\\\\VScode\\\\hail tool\\\\exported_data\\\\phenotypes\\\\cov.txt\", index=False, sep='\\t')\n",
    "\n",
    "for index,row in cov.iterrows():\n",
    "    if row['is_female']==True:\n",
    "        cov.at[index, 'is_female']=1\n",
    "    elif row['is_female']==False:\n",
    "        cov.at[index, 'is_female']=0\n",
    "\n",
    "cov.to_csv('exported_Gene_Data/phenotypes/filtered_cov.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1504f-122d-435d-9cad-8474e9f3422a",
   "metadata": {},
   "source": [
    "#### Performing the GWAS using REGENIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9622f0-0691-4895-9d7e-4d5e235d449a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Runs the first step of regenie, which fits a ridge regression model to predict phenotypes based on covariates and genotype principal components.\n",
    "regenie \\\n",
    "--step 1 \\\n",
    "--bed \"exported_Gene_Data/PLINK_genotypes/geno\" \\\n",
    "--covarFile \"exported_Gene_Data/phenotypes/filtered_cov.txt\" \\\n",
    "--catCovarList \"is_female\" \\\n",
    "--phenoFile \"exported_Gene_Data/phenotypes/filtered_pheno.txt\" \\\n",
    "--bsize 200 \\\n",
    "--out \"regenie_output/step1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c8f89-6f25-4041-bdf4-e0e10b1100bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Runs the second step of regenie, where it tests each genetic variant for association with the phenotype(s) while controlling for confounding effects.\n",
    "regenie \\\n",
    "--step 2 \\\n",
    "--bed \"exported_Gene_Data/PLINK_genotypes/geno\" \\\n",
    "--phenoFile \"exported_Gene_Data/phenotypes/filtered_pheno.txt\" \\\n",
    "--bsize 200 \\\n",
    "--pred \"regenie_output/step1_pred.list\" \\\n",
    "--out \"regenie_output/step2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88416f72-3a1f-4617-abc8-1efcbffb97ae",
   "metadata": {},
   "source": [
    "#### Post modifications of GWAS output file to make the non-numerical CME match the SNP ID ('CME' : 'gene_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c1a17-48fd-4ed6-bd45-8215061d0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regenie_output/step2_caffeine_consumption.regenie', 'r') as file:\n",
    "    content = file.read()\n",
    "pattern = r'\\b23\\b'\n",
    "updated_regenie = re.sub(pattern, 'X' , content)\n",
    "\n",
    "with open('regenie_output/step2_caffeine_consumption_updated.regenie', 'w') as file:\n",
    "    file.write(updated_regenie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071b14a-751b-4527-8856-33c4e4bfc16d",
   "metadata": {},
   "source": [
    "#### Creating a CSV file of the GWAS results from regenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588ec4d-6211-4660-b63a-b97ac1cf1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a new matrix table from the output file of regenie\n",
    "regenie_table = hl.import_table('regenie_output/step2_caffeine_consumption_updated.regenie', delimiter=' ')\n",
    "\n",
    "regenie_table = regenie_table.annotate(locus=hl.locus(regenie_table.CHROM, hl.int(regenie_table.GENPOS)))\n",
    "regenie_table = regenie_table.annotate(LOG10P=hl.float64(regenie_table.LOG10P))\n",
    "regenie_table = regenie_table.annotate(p_values=hl.float64(10**-regenie_table.LOG10P))\n",
    "\n",
    "regenie_table.export(\"regenie_output/GWAS_results.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7a721-cb01-44ac-8fb2-93f207293684",
   "metadata": {},
   "source": [
    "## <i>Now it's time to map these raw SNPs to their genes based on their genomic position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f6c60-7fa5-4647-92ae-ee5ead57adf4",
   "metadata": {},
   "source": [
    "#### Retrieve Homo Sapien gene data from Biomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123c54f-43c4-4781-bc06-c11dc46bb515",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = BiomartServer(\"http://www.ensembl.org/biomart\")\n",
    "dataset = server.datasets['hsapiens_gene_ensembl']\n",
    "\n",
    "# Define the attributes to retrieve\n",
    "attributes = ['chromosome_name', 'start_position', 'end_position', 'external_gene_name', 'ensembl_gene_id', 'entrezgene_id']\n",
    "\n",
    "# Perform the query and retrieve the results\n",
    "result = dataset.search({\n",
    "    'attributes': attributes\n",
    "})\n",
    "\n",
    "gene_data = result.text\n",
    "\n",
    "gene_df = pd.read_csv(io.StringIO(gene_data), delimiter=\"\\t\", names=attributes)\n",
    "gene_df['entrezgene_id'] = gene_df['entrezgene_id'].astype('Int64')  # Use 'Int64' for nullable integers\n",
    "\n",
    "gene_df.to_csv('HomoSapien_genes/HS_genes.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90395a9a-f5a2-47b4-836d-5899135518bf",
   "metadata": {},
   "source": [
    "#### Function to map non-numeral CMEs to integers for initial sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f615c5d-f3c8-4c3a-a1b3-be2a5b3c92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sort_key(val):\n",
    "    pattern = r'\\b\\d\\d?\\b'\n",
    "    \n",
    "    if re.match(pattern, val):\n",
    "        return int(val)\n",
    "    else:\n",
    "        chrom_order = {'X': 23, 'Y': 24, \"MT\":25}\n",
    "        return chrom_order.get(val, 26)\n",
    "\n",
    "df = pd.read_csv(\"HomoSapien_genes/HS_genes.txt\", sep='\\t')\n",
    "df.columns=[\"chrom\", \"start\", \"end\", \"gene_name\", \"Ensembl_gene_id\", \"NCBI_gene_ID\"]\n",
    "df_sorted = df.sort_values(by=['chrom', 'start'], key=lambda x: x.map(custom_sort_key) if x.name=='chrom' else x)\n",
    "df_sorted.to_csv('HomoSapien_genes/HS_initial_sorted_genes.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc6a58-51eb-4322-b798-36c1f3521b16",
   "metadata": {},
   "source": [
    "#### Enhance the sorting process of the genes file retrieved from Biomart by separating numerical CME from non-numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77405a4d-105d-4f8c-a973-0095cf331c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps for indexing the genes file since running a direct sort on the file does not do the trick \n",
    "%%bash\n",
    "total=$(cat \"HomoSapien_genes/HS_initial_sorted_genes.txt\" | wc -l)\n",
    "last_CME_line_with_MT=$(cat \"HomoSapien_genes/HS_initial_sorted_genes.txt\" | grep -n \"^MT\" | tail -1 | cut -d \":\" -f1)\n",
    "diff=$((total-last_CME_line_with_MT))\n",
    "\n",
    "head -$last_CME_line_with_MT \"HomoSapien_genes/HS_initial_sorted_genes.txt\" > \"HomoSapien_genes/HS_sorted_CME.txt\"\n",
    "tail -$diff \"HomoSapien_genes/HS_initial_sorted_genes.txt\" > \"HomoSapien_genes/HS_unsorted_haplotypes.txt\"\n",
    "sort -k1,1 -k2,2n \"HomoSapien_genes/HS_unsorted_haplotypes.txt\" > \"HomoSapien_genes/HS_sorted_haplotypes.txt\"\n",
    "cat HS_sorted_CME.txt \"HomoSapien_genes/HS_sorted_haplotypes.txt\" > \"HomoSapien_genes/HS_final_sorted_genes.txt\"\n",
    "\n",
    "# indexing the sorted file to easily extract data from it\n",
    "bgzip \"HomoSapien_genes/HS_final_sorted_genes_copy.txt\"\n",
    "tabix -p bed \"HomoSapien_genes/HS_final_sorted_genes_copy.txt.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce712379-b28a-4d4f-8495-19cadd345d62",
   "metadata": {},
   "source": [
    "#### Script to retrieve gene data from raw SNP input: CME and SNP position (allows for discovery of new SNPs that are not recorded in the database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9858b-6ee4-43a7-928d-9441b50593bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\\\\scripts\\\\gene_script.py\"\n",
    "import pysam\n",
    "import argparse\n",
    "\n",
    "def find_genes_with_snp(tabix_file, chrom, pos):\n",
    "    if chrom == 23:\n",
    "        chrom = 'X'\n",
    "    region = f\"{chrom}:{pos-1}-{pos}\"     #pos-1 and pos to narrow down the search as much as possible\n",
    "    genes_containing_snp = []\n",
    "    \n",
    "    for entry in tabix_file.fetch(region=region):     #it will retrieve all entries/genes that overlap with the specified region\n",
    "        fields = entry.split('\\t')\n",
    "        gene_chrom = fields[0]\n",
    "        gene_start = int(fields[1])\n",
    "        gene_end = int(fields[2])\n",
    "        gene_name = fields[3]\n",
    "        gene_NCBI_id = fields[5]\n",
    "        genes_containing_snp.append((gene_name, gene_NCBI_id, gene_start, gene_end))\n",
    "    if len(genes_containing_snp) == 0:\n",
    "        return \"None\"\n",
    "    if len(genes_containing_snp) == 1:\n",
    "        return genes_containing_snp[0]\n",
    "    else:    #case of nested genes\n",
    "        gene_of_interest = genes_containing_snp[0]\n",
    "        min_start = gene_of_interest[2]\n",
    "        min_end = gene_of_interest[3]\n",
    "        for gene in genes_containing_snp:\n",
    "            if gene[2] < min_start and gene[3] < min_end:\n",
    "                gene_of_interest = gene\n",
    "                min_start = gene[2]\n",
    "                min_end = gene[3]\n",
    "        return gene_of_interest\n",
    "    \n",
    "compressed_file=\"HomoSapien_genes/HS_final_sorted_genes_copy.txt.gz\"\n",
    "tabix_file = pysam.TabixFile(compressed_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Find genes containing SNP.')\n",
    "    parser.add_argument('--snp_chrom', type=int, required=True, help='Chromosome of the SNP')\n",
    "    parser.add_argument('--snp_pos', type=int, required=True, help='Position of the SNP')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    genes = find_genes_with_snp(tabix_file, args.snp_chrom, args.snp_pos)\n",
    "    print(genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be77953-8328-4627-9edc-a488ddca22bc",
   "metadata": {},
   "source": [
    "#### vcf_script file used to update the GWAS dataframe with genes of known SNPs from ncbi local database of SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcaf8d3-97ec-4566-8928-48c5283c616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"C:\\\\Rami\\\\Career_Experience\\\\Andreas_Henschel\\\\Project\\\\Material_used\\\\scripts\\\\vcf_script.py\"\n",
    "#Script to create a GWAS dataframe with all data I retrieved for the raw SNPs\n",
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "def find_snp(vcf_file):                                    \n",
    "    for i in range(len(GWAS_df)):                              \n",
    "        chrom = GWAS_df['CHROM'][i]                            \n",
    "        SNP_pos = GWAS_df['GENPOS'][i]\n",
    "        records = vcf_file.fetch(chrom, SNP_pos-1, SNP_pos)\n",
    "        #example of record:\n",
    "        #CHROM     POS        ID      REF   ALT   QUAL  FILTER   INFO\n",
    "        #1        55550    rs1234567   G     A     .      .     'dict object'\n",
    "\n",
    "        for record in records:   #loop needed because 'records' is an iterator object (even if only one match)\n",
    "            record_info = dict(record.info)  #example entry{'RS': 775809821, 'RSPOS': 10020, 'dbSNPBuildID': 144, 'SSR': 0, 'SAO': 0, 'VP': '0x050000020005000002000200', 'GENEINFO': 'DDX11L1:100287102', 'WGT': 1, 'VC': 'DIV', 'R5': True, 'ASP': True}\n",
    "            if 'GENEINFO' in record_info:\n",
    "                gene_info = record_info['GENEINFO'].split(\":\")\n",
    "                GWAS_df.loc[(GWAS_df[\"CHROM\"] == record.chrom) & (GWAS_df['GENPOS'] == record.pos), \"Gene_name\"] = gene_info[0]\n",
    "                GWAS_df.loc[(GWAS_df[\"CHROM\"] == record.chrom) & (GWAS_df['GENPOS'] == record.pos), \"NCBI_ID\"] = gene_info[1]\n",
    "            GWAS_df.loc[(GWAS_df[\"CHROM\"] == record.chrom) & (GWAS_df['GENPOS'] == record.pos), \"ID\"] = record.id\n",
    "\n",
    "def search_gene(CHROM, SNP):\n",
    "    # Whether the Gene name is known or not, we still need to go back to the 'genes file' to retrieve the start and end positions of this gene\n",
    "    command = f'wsl python3 scripts/gene_script.py --snp_chrom {CHROM} --snp_pos {SNP}'\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    # Check the output\n",
    "    out = result.stdout.strip()\n",
    "    if out == \"None\":\n",
    "        return \"None\"\n",
    "    else:\n",
    "        try:\n",
    "            result_list = ast.literal_eval(out)  # Safely evaluate the string to a list\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing result_str: {result_str}\")\n",
    "        return result_list\n",
    "\n",
    "\n",
    "GWAS_df = pd.read_csv(\"regenie_output/GWAS_results.txt\", sep='\\t')\n",
    "\n",
    "GWAS_df[\"Gene_name\"] = 'NA'  #Use this column for when you find the Gene of the SNP; replace NA with gene name.\n",
    "GWAS_df['NCBI_ID'] = 'NA'\n",
    "GWAS_df[\"GENPOS\"] = GWAS_df[\"GENPOS\"].astype('int64')\n",
    "\n",
    "GWAS_df[\"CHROM\"] = GWAS_df[\"CHROM\"].replace({\"X\":\"23\"})\n",
    "GWAS_df[\"CHROM\"] = GWAS_df[\"CHROM\"].astype('int64')\n",
    "\n",
    "GWAS_df[\"color\"] = GWAS_df['CHROM'].apply(lambda x : 'blue' if x%2==0 else 'black')   #For coloring purposes of manhattan plot\n",
    "GWAS_df['def_color'] = GWAS_df['color']\n",
    "\n",
    "\n",
    "compressed_file=\"local_SNP_database/00-All.vcf.gz\"\n",
    "vcf_file = pysam.VariantFile(compressed_file)\n",
    "find_snp(vcf_file)\n",
    "\n",
    "#Some SNPs were not caught identified using the find_SNP function but they have data from the manually sorted HS_final_sorted_genes_copy.txt.gz file\n",
    "#So, I am going to loop over the entire GWAS_df ONCE, find the gene_names of the unidentified SNPs using the search_gene() function.\n",
    "for index, row in GWAS_df.iterrows():\n",
    "    if type(row['Gene_name']) == float:  #if it is null object (no gene name)\n",
    "        gene_info = search_gene( row['CHROM'] , row['GENPOS'] )\n",
    "        \n",
    "        if gene_info != 'None':\n",
    "            GWAS_df.loc[index, 'Gene_name'] = gene_info[0]\n",
    "            if gene_info[1] != '':\n",
    "                GWAS_df.loc[index, 'NCBI_ID'] = int(float(gene_info[1]))\n",
    "\n",
    "\n",
    "#We want to add a column that will keep track of the cumulative positions of the SNPs for manhattan plot\n",
    "start_pos_relative_to_genome = 0\n",
    "cumulative_list = []\n",
    "\n",
    "#groupby(\"CHROM\") groups the CHROM column where the name of the group is the chromosome and the group is a subset of the dataframe whose chrom is of that group\n",
    "for chrom, group in GWAS_df.groupby(\"CHROM\"):\n",
    "    cumulative_list.append(group[\"GENPOS\"] + start_pos_relative_to_genome)    #store the positions of the SNPs relative to the genome, starts with 0 then the max SNP of chrom 1 and so on..\n",
    "    start_pos_relative_to_genome += group[\"GENPOS\"].max()\n",
    "GWAS_df[\"cumulative_pos\"] = pd.concat(cumulative_list)\n",
    "\n",
    "GWAS_df[\"CHROM\"] = GWAS_df[\"CHROM\"].astype(str)\n",
    "GWAS_df[\"CHROM\"] = GWAS_df[\"CHROM\"].replace({\"23\":\"X\"})\n",
    "\n",
    "GWAS_df.to_csv('GWAS_df_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97117a-9920-43ae-b7c9-2b1bf2233d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wsl python3 \"scripts/vcf_script.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea25186-8077-4fdf-b951-8218af230ea8",
   "metadata": {},
   "source": [
    "## <i>Now we want to study gene associations with the trait (allows us to expand on the traditional GWAS to look at genes' and bio pathways' impact on a trait)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be87e1-6547-4c73-891e-93d6fa5b544e",
   "metadata": {},
   "source": [
    "#### Setting up the GWAS summary statistics file for MAGMA (Needed for gene level association testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9069a-d4e8-4aae-a58f-42f8994c0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWAS_df = pd.read_csv('GWAS_df_updated.csv')\n",
    "GWAS_df.drop(['EXTRA', 'TEST', 'Gene_name', 'NCBI_ID', 'color', 'def_color', 'cumulative_pos'], axis=1, inplace=True)\n",
    "GWAS_df.to_csv('MAGMA_files/GWAS_summary_stat.txt', sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4b181-3384-4fa6-a4e3-dda5d4e8959c",
   "metadata": {},
   "source": [
    "#### Setting up the annotation files for MAGMA (Needed for gene level association testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870969d-09bd-4c5e-bcb5-44da02de18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWAS_df[['ID', 'CHROM', 'GENPOS']].to_csv('MAGMA_files/Gene-SNP_mapping_input_files/SNPLOC_file.txt', header=False, sep='\\t', index=False)\n",
    "\n",
    "#To map the genes to the SNPs\n",
    "magma --annotate\n",
    "      --snp-loc 'Gene-SNP_mapping_input_files/SNPLOC_file.txt'\n",
    "      --gene-loc 'Gene-SNP_mapping_input_files/NCBI38.gene.loc'   #This file was downloaded from https://cncr.nl/research/magma/, gene_locations build38\n",
    "      --out 'Gene-SNP_mapping_output_files/annotation_file'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f2286-af16-4caf-b28f-acef079aa44f",
   "metadata": {},
   "source": [
    "#### Setting up PLINK files for MAGMA (Needed for gene level association testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d33c7-76e7-4ae6-a194-aa39be8f3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CME', 'SNP_id', 'something', 'GENPOS', 'original_nuc', 'polymorphism']\n",
    "\n",
    "#modify the SNP ids of the geno.bim file\n",
    "geno_bim = pd.read_csv('exported_Gene_Data/PLINK_genotypes/geno.bim', sep = '\\t', names = columns, header = None)\n",
    "\n",
    "for index, row in geno_bim.iterrows():\n",
    "    gwas_row_snp_id = GWAS_df.loc[index]['ID']\n",
    "    \n",
    "    if gwas_row_snp_id != row['SNP_id']:\n",
    "        geno_bim.loc[index, 'SNP_id'] = gwas_row_snp_id\n",
    "    if index == 9765:\n",
    "        break\n",
    "geno_bim.to_csv('MAGMA_files/MAGMA_PLINK_geno/magma_genotypes/magma_geno.bim', sep = '\\t', index = False, header = None)\n",
    "\n",
    "#Then, copy paste the other geno files (.bed and .fam) from exported_Gene_Data/PLINK_genotypes into same folder as geno.bim (magma_genotypes)\n",
    "\n",
    "# PLINK reformats the genotype files (.bam .bed .bim) into binary format and updates them based on any changes in SNPs or sample IDs.\n",
    "!wsl plink --bfile 'MAGMA_files/MAGMA_PLINK_geno/magma_genotypes/magma_geno' --make-bed --out 'MAGMA_files/MAGMA_PLINK_geno/updated_magma_genotypes/updated_magma_geno'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63921096-dbfa-4c14-a85e-11f53972b95c",
   "metadata": {},
   "source": [
    "#### Setting up GENE-SETs.txt for gene-set level association study (Association of sets of genes with a trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a927b51-92f9-4846-ba8a-9d65bd8327ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We use reactome2py to retrieve the pathways every gene is part of and perform the classification\n",
    "import reactome2py\n",
    "from reactome2py import content\n",
    "\n",
    "pathways_with_IDs_dict = {}\n",
    "\n",
    "for index, row in GWAS_df.iterrows():\n",
    "    ncbi_gene_id = row[\"NCBI_ID\"]\n",
    "\n",
    "    if ncbi_gene_id is not None:\n",
    "        pathways = reactome2py.content.mapping(id=ncbi_gene_id, resource='NCBI gene', species='9606', by='pathways')\n",
    "        if pathways is not None:\n",
    "            for path in pathways: #each path is a dictionary\n",
    "                path_id = path['stId']\n",
    "                if path_id not in pathways_with_IDs_dict.keys():\n",
    "                    pathways_with_IDs_dict[path_id] = []\n",
    "                    \n",
    "                if ncbi_gene_id not in pathways_with_IDs_dict[path_id]:\n",
    "                    pathways_with_IDs_dict[path_id].append(ncbi_gene_id)\n",
    "\n",
    "df = pd.DataFrame.from_dict(pathways_with_IDs_dict, orient='index')  #This makes each key as the row and its values as entries in the column cells\n",
    "df = df.reset_index()  #This makes the pathway name as a separate column instead of \"index\"\n",
    "df = df.fillna('')  #We need to replace the empty cells (represented as 'NA'/None by pandas) to avoid trailing commas when converting to txt file\n",
    "df.to_csv(\"MAGMA_files/GENE-SETs.txt\", header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfae37b-eaea-4f48-b065-77d0b41677a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do the gene analysis based off of their mapped SNPs(get the p-value of every gene)\n",
    "#This is a prerequisite to the gene-set analysis that we are aiming for\n",
    "magma --bfile 'MAGMA_PLINK_geno/updated_magma_geno'\n",
    "      --pval GWAS_summary_stat.txt pval=p_values snp-id=ID ncol=N\n",
    "      --gene-annot \"MAGMA_files/Gene-SNP_mapping_output_files/annotation_file.genes.annot\"\n",
    "      --out \"MAGMA_gene_analysis/gene_results\"\n",
    "\n",
    "#This is the gene-set analysis which is used to identify which sets of genes are mostly associated with the trait (larger scale than just SNPs)\n",
    "\n",
    "#Competitive gene set analysis: Tests if genes in a set are more strongly associated with the trait than all other genes in the genome.\n",
    "magma --gene-results MAGMA_gene_analysis/gene_results.genes.raw\n",
    "      --set-annot GENE_SETs.txt\n",
    "      --out MAGMA_gene-set_analysis/competitive_gene_set_analysis\n",
    "\n",
    "#Self-contained get-set analysis: Tests only genes within a gene set, without comparing them to other genes.\n",
    "#(is not very informative if we feed magma all the genes of the genome)\n",
    "#However, if we provide a specific predefined set of genes (example: inflammation-related), then it would be very powerful\n",
    "magma --gene-results MAGMA_gene_analysis/gene_results.genes.raw\n",
    "      --set-annot GENE-SETs.txt\n",
    "      --out MAGMA_gene-set_analysis/self-contained_analysis\n",
    "      --model self-contained\n",
    "      --settings gene-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7e8d6-7e9f-42be-bf63-0b0bad860d91",
   "metadata": {},
   "source": [
    "#### If GO_analysis manhattan plots are desired to be used later on, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bf06d-f3e9-4b1b-9919-d6d047155cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import goatools\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.associations import read_gaf\n",
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.base import download_ncbi_associations\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS\n",
    "import pronto\n",
    "\n",
    "download_go_basic_obo(\"GO/\")        #This retrieves all the gene ontology terms ever recorded;\n",
    "                                    #it holds the definitions, relationships, and hierarchical structure of all the terms in the GO.\n",
    "    \n",
    "obodag = GODag(\"GO/go-basic.obo\")   #Parses the downloaded GO ontology file (streuctures them based on relationships)\n",
    "  \n",
    "url = \"https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz\"   #The file from this link maps the GO associations with all well-studied and GO-annotated genes; needs to be downloaded then unzipped \n",
    "                                                            #I stored it as \"gene2go\"\n",
    "    \n",
    "objanno = Gene2GoReader(\"GO/gene2go\", godag=obodag, taxids=[9606])   #We use \"gene2go\" (unzipped) to extract the GO mappings of only the homo sapiens genes\n",
    "\n",
    "ontology = pronto.Ontology('GO/go-basic.obo')        #similar to obodag but it also carries the definition/description of every GO term\n",
    "\n",
    "d = objanno.get_id2gos()   # dictionary where keys are NCBI IDs and values are GO terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89f783-d1d2-4a00-a6b5-14793d2b8568",
   "metadata": {},
   "source": [
    "## <i>In this upcoming blocks of code, different functions have been defined to visualize GWAS results in an interacive way with the user</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd982b-da07-4bda-bd65-f5fbbf1212bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWAS_df = pd.read_csv('GWAS_df_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584a19c-4d24-413e-9081-055101ec82ef",
   "metadata": {},
   "source": [
    "#### function to create an interactive manhattan plot using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9537c8-f330-4b9a-ad7d-9e8555a0c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(color, color_map, df=GWAS_df, highlight_color=None):\n",
    "    if highlight_color==None:  #Inital plot to display\n",
    "        fig = px.scatter(\n",
    "        df,\n",
    "        x=\"cumulative_pos\",\n",
    "        y=\"LOG10P\",\n",
    "        color= color,\n",
    "        labels={\"cumulative_pos\": \"Chromosome\", \"LOG10P\": \"-log10(p-value)\"},  # Axis labels\n",
    "        color_discrete_map=color_map,\n",
    "        hover_data={\n",
    "                    \"locus\":True,\n",
    "                    \"color\":False, \"cumulative_pos\": False\n",
    "                   }  # You can add more hover data if needed\n",
    "        )\n",
    "    else:\n",
    "        fig = px.scatter(\n",
    "        df,\n",
    "        x=\"cumulative_pos\",\n",
    "        y=\"LOG10P\",\n",
    "        color= color,\n",
    "        labels={\"cumulative_pos\": \"Chromosome\", \"LOG10P\": \"-log10(p-value)\"},  # Axis labels\n",
    "        color_discrete_map=color_map,\n",
    "        hover_data={\n",
    "                    \"locus\":True,\n",
    "                    \"color\":False, \"cumulative_pos\": False, highlight_color:False\n",
    "                   }  # You can add more hover data if needed\n",
    "        )\n",
    "    \n",
    "    # Customize x-axis ticks to show chromosomes in the middle of each block\n",
    "    df[\"CHROM\"] = df[\"CHROM\"].replace({\"X\":\"23\"})\n",
    "    df[\"CHROM\"] = df[\"CHROM\"].astype('int64')\n",
    "    chrom_medians = df.groupby(\"CHROM\")[\"cumulative_pos\"].median()\n",
    "    chroms = df['CHROM'].unique().tolist()\n",
    "    chroms[-1] = 'X'\n",
    "    fig.update_xaxes(\n",
    "        tickvals=chrom_medians,  # Set the positions of ticks to the median cumulative position\n",
    "        ticktext = chroms # Set the labels to chromosome names\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',  # Changes the background color of the plot area\n",
    "        xaxis=dict(showgrid=True,\n",
    "                   gridcolor='lightblue',\n",
    "                    zeroline=True,          # Show the x-axis (zeroline)\n",
    "                    zerolinecolor='black',  # Set x-axis line color\n",
    "                    showticklabels=True,   # Hide x-axis tick labels\n",
    "                    showline=False         # Hide the axis line outside the plot),\n",
    "                  ),\n",
    "        yaxis=dict(showgrid=True,\n",
    "                   gridcolor='lightblue',\n",
    "                    zeroline=True,          # Show the x-axis (zeroline)\n",
    "                    zerolinecolor='black',  # Set x-axis line color\n",
    "                    showticklabels=True,   # Hide x-axis tick labels\n",
    "                    showline=False)   # Hides grid lines on the y-axis\n",
    "    )\n",
    "    # Remove markers' outlines (similar to linewidth=0 in Seaborn)\n",
    "    fig.update_traces(marker=dict(line=dict(width=0)), showlegend=False)\n",
    "    \n",
    "    # Show the interactive plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37ccd8-78e0-49b7-a570-cdf5b0686964",
   "metadata": {},
   "source": [
    "#### Processes a list of SNP loci to find them on the manhattan plot and highlight them for the user to see their p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06fa20-d552-4d3c-b32e-487780b432ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_box(loci_list):\n",
    "         count=0\n",
    "         \n",
    "         for locus in loci_list:\n",
    "            SNP_info = GWAS_df.loc[GWAS_df['locus'] == locus]\n",
    "            \n",
    "            if (pd.isna(SNP_info['Gene_name']).iloc[0] == True) and (pd.isna(SNP_info['NCBI_ID']).iloc[0] == True):  #Both are None; iloc[0] is to make sure we take only the first row of the series (it is going to be 1 anyway)\n",
    "                info_text.value += f\"SNP '{locus}' is not found in any known genes<br>\"\n",
    "                count+=1\n",
    "            else:\n",
    "                flag = 0\n",
    "                if pd.isna(SNP_info['NCBI_ID'].iloc[0]) == False:\n",
    "                    ncbi_id = SNP_info['NCBI_ID'].unique()\n",
    "                    SNPs_of_gene = GWAS_df.loc[GWAS_df['NCBI_ID'].isin(ncbi_id)]\n",
    "                    flag = 1\n",
    "                    \n",
    "                \n",
    "                if pd.isna(SNP_info['Gene_name'].iloc[0]):  #if the name of the gene is unknown\n",
    "                    info_text.value += f\"SNP '{locus}' is found in a gene of ID: {ncbi_id[0]}<br>\"\n",
    "                else:\n",
    "                    gene_name = SNP_info['Gene_name'].unique()\n",
    "                    if flag == 1:\n",
    "                        SNPs_of_gene = GWAS_df.loc[GWAS_df['Gene_name'].isin(gene_name)]\n",
    "                        \n",
    "                    info_text.value += f\"SNP '{locus}' is found in gene {gene_name[0]}<br>\"\n",
    "                \n",
    "                #highlight the SNP by coloring it\n",
    "                gene_color = \"rgb({},{},{})\".format(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "                while (gene_color == 'rgb(0, 0, 255)' or gene_color == \"rgb(0, 0, 0)\") or gene_color == \"rgb(255, 255, 255)\":\n",
    "                    gene_color = \"rgb({},{},{})\".format(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "    \n",
    "                GWAS_df.loc[SNPs_of_gene.index, 'color'] = gene_color\n",
    "                        \n",
    "                if \"highlight_color\" not in GWAS_df.columns:    # if it is the first SNP of the list\n",
    "                            GWAS_df[\"highlight_color\"] = GWAS_df.apply(\n",
    "                                            lambda row:gene_color\n",
    "                                            if row['Gene_name']==SNP_info['Gene_name'].iloc[0] else row[\"color\"], axis=1)\n",
    "                else:\n",
    "                            GWAS_df[\"highlight_color\"] = GWAS_df.apply(\n",
    "                                            lambda row:gene_color\n",
    "                                            if row['Gene_name']==SNP_info['Gene_name'].iloc[0] else row[\"highlight_color\"], axis=1)\n",
    "         \n",
    "         if count==len(loci_list):\n",
    "        #if all SNPs are not part of known genes, no need to plot figure\n",
    "             pass\n",
    "         else:\n",
    "             with plot_output:\n",
    "                        color=\"highlight_color\"\n",
    "                        color_map={\"black\": \"black\", \"blue\": \"blue\", gene_color:gene_color}\n",
    "                        plot(color, color_map, GWAS_df, \"highlight_color\")\n",
    "\n",
    "         GWAS_df['color'] = GWAS_df['def_color']\n",
    "         GWAS_df.drop('highlight_color', axis=1, inplace=True)\n",
    "\n",
    "def update_info(change):\n",
    "    loci = change['new'].split(',')\n",
    "    for locus in loci:\n",
    "        locus = str(locus)\n",
    "    text_box(loci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8eb9c0-7cbd-4b43-bbef-ad7224bbd446",
   "metadata": {},
   "source": [
    "#### Functions to display manhattan plot of related genes (user inputs in what way they are related (eg. inflammation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8368467-2932-4ed5-ac0c-d50848d19b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GO_analysis(keyword):\n",
    "    # we go over the SNPs that carry an NCBI_ID. After that, we check in d (objanno.get_id2gos()) the GO_terms of that gene.\n",
    "    # If the gene is related to our keyword (eg. inflammation), we add it to the new dataframe.\n",
    "    # After that, we plot this new dataframe which holds SNPs whose genes have GO-terms relating to inflammation\n",
    "\n",
    "    SNPs_with_NCBI_IDs = GWAS_df.loc[GWAS_df['NCBI_ID'].notna()]\n",
    "    gene_ids = SNPs_with_NCBI_IDs[\"NCBI_ID\"].unique()    #stored as set\n",
    "    \n",
    "    SNPs_related_to_term_df = pd.DataFrame(columns = GWAS_df.columns) # an empty dataframe with same columns as GWAS_df\n",
    "    \n",
    "    for ID in gene_ids:\n",
    "        if '|' in ID:  #some IDs have this form: 'NSBI_ID'| 'name'\n",
    "            ID = ID.split('|')[0]\n",
    "        ID = int(ID)\n",
    "        if ID in d.keys():\n",
    "            go_terms = d[ID] #go terms of gene stored as set\n",
    "            for term in go_terms:\n",
    "                defn = ontology[term].definition\n",
    "                if keyword in defn:\n",
    "                    new_row = SNPs_with_NCBI_IDs.loc[SNPs_with_NCBI_IDs['NCBI_ID'] == str(ID)]\n",
    "                    SNPs_related_to_term_df = pd.concat([SNPs_related_to_term_df, new_row], ignore_index=True)\n",
    "                    break  #it is enough to find only one GO-term that satisfies the condition\n",
    "                    \n",
    "    return SNPs_related_to_term_df\n",
    "\n",
    "def update_GO(change):\n",
    "    keyword = change['new']\n",
    "    GO(keyword)\n",
    "\n",
    "def GO(keyword):\n",
    "    GO_term_df = GO_analysis(keyword)\n",
    "    with plot_output:\n",
    "            color= \"color\"\n",
    "            color_map={\"black\": \"black\", \"blue\": \"blue\"}\n",
    "            plot(color, color_map, GO_term_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbf73f-0838-4ec8-aa48-84977353bc42",
   "metadata": {},
   "source": [
    "#### Calls all the functions to display the manhattan plot and interactive widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7cc38-7383-4dd5-944f-5fcc513532db",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_text = widgets.Text(value='', placeholder='SNP locus/loci as \"CME:SNP\"', description='Comma-Separated SNPs:', continuous_update=False)\n",
    "info_text = widgets.HTML(value='', description='Info:')\n",
    "Gene_ontology = widgets.Text(value='', placeholder='Enter Gene ontology term', description='GO:', continuous_update = False)\n",
    "\n",
    "plot_output = widgets.Output()\n",
    "snp_text.observe(update_info, names=\"value\")\n",
    "\n",
    "#make sure to run the GO cell to prepare the dictionary d (objanno.get_id2gos())\n",
    "Gene_ontology.observe(update_GO, names = \"value\")\n",
    "\n",
    "display(snp_text, info_text, Gene_ontology, plot_output)\n",
    "\n",
    "with plot_output:\n",
    "    color= \"color\"\n",
    "    color_map={\"black\": \"black\", \"blue\": \"blue\"}\n",
    "    plot(color, color_map, GWAS_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec19194-753e-449a-870e-8b05d76d163d",
   "metadata": {},
   "source": [
    "## <i>This is where I stopped. The project was taking a machine learning approach where we use heirarchical data for feature engineering (something similar to : https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2205-3 )</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e78b59-5ac1-4d5c-9a00-1d7942d38a29",
   "metadata": {},
   "source": [
    "#### Algorithm to create hierarchical tree structures of the biological pathways to better understand their relationships and p-values (not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd085546-1098-47b8-9d22-2bd4afdb372f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import reactome2py\n",
    "from reactome2py import content\n",
    "\n",
    "p_values = {}\n",
    "with open('pathways_names_dict.pkl', 'rb') as file:  #'rb': read binary\n",
    "    pathways_names_dict = pickle.load(file)\n",
    "    \n",
    "with open('MAGMA_files/GENE-SETs.txt', 'r') as file1, open('MAGMA_files/MAGMA_gene-set_analysis/self-contained_analysis.gsa.out', 'r') as file2:\n",
    "\n",
    "    for _ in range(5):  #skip the first 4 lines to avoid description and header lines\n",
    "        next(file2)\n",
    "        \n",
    "    for line1, line2 in zip(file1, file2):    #loop stops when the shorter file (file2) ends \n",
    "        nodedict = {}\n",
    "        edgelist = []\n",
    "        line1 = line1.strip()\n",
    "        line2 = line2.strip()\n",
    "        L1 = line1.split(\"\\t\")\n",
    "        L2 = line2.split(\"      \")   #columns separated by 6 spaces\n",
    "        \n",
    "        path_id = L1[0]\n",
    "        p_value_of_path_id = L2[-1]\n",
    "        \n",
    "        if path_id not in nodedict.keys():\n",
    "            nodedict[path_id] = pathways_names_dict[path_id]\n",
    "            \n",
    "        if path_id not in p_values.keys():\n",
    "            p_values[path_id] = p_value_of_path_id\n",
    "            \n",
    "        # list_of_pathways_ancestors = reactome2py.content.event_ancestors(id=path_id)[0]\n",
    "            \n",
    "        # for ancestor in list_of_pathways_ancestors:    #each ancestor is a dictionary\n",
    "        #             if 'stId' in ancestor.keys():\n",
    "        #                 ancestor_id = ancestor['stId']\n",
    "        #                 if ancestor_id not in nodedict.keys():\n",
    "        #                     nodedict[ancestor_id] = ancestor['displayName']\n",
    "                            \n",
    "        #                 if (ancestor_id, path_id) not in edgelist and ancestor_id != path_id:\n",
    "        #                     edgelist.append( (ancestor_id, path_id) )\n",
    "        #             else:\n",
    "        #                 ancestor_name = ancestor['displayName']\n",
    "        #                 if ancestor_name not in nodedict.keys():\n",
    "        #                     nodedict[ancestor_name] = ancestor['displayName']\n",
    "                            \n",
    "        #                 if ancestor_name not in edgedict[path_id]:\n",
    "        #                     edgelist.append((ancestor_name, path_id))\n",
    "        \n",
    "# with open(\"nodedict.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(nodedict, file)\n",
    "        \n",
    "# with open(\"edgelist.pkl\", \"wb\") as file:\n",
    "#         pickle.dump(edgelist, file)\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d1250-48cf-453b-9f55-dea4e0ba1348",
   "metadata": {},
   "source": [
    "#### Load the nodes and edges created into a networkx graph (not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5962b6-386d-4db6-bec8-0595d7c9f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "with open(args.nodedict_file, \"rb\") as file:\n",
    "        nodes = pickle.load(file)\n",
    "\n",
    "with open(args.edgelist_file, \"rb\") as file:\n",
    "        edges = pickle.load(file)\n",
    "    \n",
    "G = nx.DiGraph()\n",
    "\n",
    "for path_id, path_name in nodes.items():\n",
    "            G.add_node(path_id)\n",
    "G.add_edges_from(edges)\n",
    "connected_components = list(nx.weakly_connected_components(G))\n",
    "    \n",
    "for i, component in enumerate(connected_components):\n",
    "    if i == 1:\n",
    "        subgraph = G_pgv.subgraph(name=f\"cluster_{i}\")  # Create subgraph\n",
    "        for node in component:\n",
    "            subgraph.add_node(node)  # Add nodes\n",
    "                \n",
    "        edges_in_component = [edge for edge in edges if edge[0] in component and edge[1] in component]\n",
    "        for edge in edges_in_component:\n",
    "            subgraph.add_edge(*edge)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
